{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_VuovFLz81u",
        "outputId": "114da7eb-2f00-4c40-d0b2-6adf07c45f71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is enabled: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA (GPU support) is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"GPU is enabled: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, using CPU instead\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-DZPJN30O37",
        "outputId": "e9e33632-73ab-4b0e-952a-1189e7cfb3ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision pillow matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRD-kf7S0ap-",
        "outputId": "97ab58ef-94ae-47fe-c9be-d15aaf70e031"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First uninstall existing packages\n",
        "#!pip uninstall torch torchvision -y\n",
        "\n",
        "# Then reinstall with --no-cache-dir flag\n",
        "!pip install torch torchvision pillow matplotlib --no-cache-dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1fJz97t0wxC",
        "outputId": "9a250891-c1a5-4734-b691-70b328cee11e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "EIPbNTKH2z57"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "GjkcXxWX3UUT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Our Custom Dataset\n",
        "class WasteDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = ['O', 'R']  # O=Organic, R=Recyclable\n",
        "        self.image_paths = []\n",
        "\n",
        "        for i, class_name in enumerate(self.classes):\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            for img_name in os.listdir(class_dir):\n",
        "                self.image_paths.append((os.path.join(class_dir, img_name), i))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "l_92TFvY3eyB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip the dataset\n",
        "!unzip -q \"/content/drive/MyDrive/waste-classification-data.zip\" -d \"/content/dataset\""
      ],
      "metadata": {
        "id": "3FasZ_bX3jVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e338f2-1628-4c93-9172-d76588a662ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/dataset/DATASET/TEST/O/O_12568.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/dataset/DATASET/TEST/O/O_12569.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = WasteDataset('/content/dataset/DATASET/TRAIN', transform=transform)\n",
        "test_dataset = WasteDataset('/content/dataset/DATASET/TEST', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "fPD30fnm3yKw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.classifier[1] = nn.Sequential(\n",
        "    nn.Linear(model.classifier[1].in_features, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)  # Move classifier to GPU immediately\n",
        "\n",
        "model = model.to(device)  # Move entire model to GPU\n",
        "print(f\"Model moved to: {next(model.parameters()).device}\")\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.classifier[1].parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B8IHtIS30bV",
        "outputId": "c2639186-460d-4f38-ec96-c7f211566623"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model moved to: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced training loop with GPU and progress tracking\n",
        "num_epochs = 10\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        # Move data to GPU in batches\n",
        "        inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Print every 50 batches\n",
        "        if batch_idx % 50 == 0:\n",
        "            print(f'Epoch {epoch+1}, Batch {batch_idx}: Loss {loss.item():.4f}')\n",
        "\n",
        "    epoch_loss = running_loss/len(train_loader)\n",
        "    train_losses.append(epoch_loss)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Avg Loss: {epoch_loss:.4f}')\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/waste_model_gpu.pth')\n",
        "print(\"Model saved with GPU-trained weights\")\n",
        "\n",
        "# Plot training progress\n",
        "plt.plot(range(1, num_epochs+1), train_losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Progress')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bbZlarZv38GO",
        "outputId": "9cab6172-8c7a-4c0c-a24f-65b313d09dc2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 0: Loss 0.7169\n",
            "Epoch 1, Batch 50: Loss 0.2735\n",
            "Epoch 1, Batch 100: Loss 0.2448\n",
            "Epoch 1, Batch 150: Loss 0.3403\n",
            "Epoch 1, Batch 200: Loss 0.2577\n",
            "Epoch 1, Batch 250: Loss 0.1613\n",
            "Epoch 1, Batch 300: Loss 0.2181\n",
            "Epoch 1, Batch 350: Loss 0.2903\n",
            "Epoch 1, Batch 400: Loss 0.2573\n",
            "Epoch 1, Batch 450: Loss 0.2069\n",
            "Epoch 1, Batch 500: Loss 0.1398\n",
            "Epoch 1, Batch 550: Loss 0.1445\n",
            "Epoch 1, Batch 600: Loss 0.1894\n",
            "Epoch 1, Batch 650: Loss 0.2521\n",
            "Epoch 1, Batch 700: Loss 0.1970\n",
            "Epoch 1/10, Avg Loss: 0.2755\n",
            "Epoch 2, Batch 0: Loss 0.4372\n",
            "Epoch 2, Batch 50: Loss 0.1752\n",
            "Epoch 2, Batch 100: Loss 0.4401\n",
            "Epoch 2, Batch 150: Loss 0.5186\n",
            "Epoch 2, Batch 200: Loss 0.2832\n",
            "Epoch 2, Batch 250: Loss 0.1692\n",
            "Epoch 2, Batch 300: Loss 0.3205\n",
            "Epoch 2, Batch 350: Loss 0.3231\n",
            "Epoch 2, Batch 400: Loss 0.2066\n",
            "Epoch 2, Batch 450: Loss 0.2284\n",
            "Epoch 2, Batch 500: Loss 0.1328\n",
            "Epoch 2, Batch 550: Loss 0.1719\n",
            "Epoch 2, Batch 600: Loss 0.3083\n",
            "Epoch 2, Batch 650: Loss 0.2494\n",
            "Epoch 2, Batch 700: Loss 0.1797\n",
            "Epoch 2/10, Avg Loss: 0.2457\n",
            "Epoch 3, Batch 0: Loss 0.2416\n",
            "Epoch 3, Batch 50: Loss 0.4415\n",
            "Epoch 3, Batch 100: Loss 0.3196\n",
            "Epoch 3, Batch 150: Loss 0.2114\n",
            "Epoch 3, Batch 200: Loss 0.3822\n",
            "Epoch 3, Batch 250: Loss 0.2076\n",
            "Epoch 3, Batch 300: Loss 0.2351\n",
            "Epoch 3, Batch 350: Loss 0.2082\n",
            "Epoch 3, Batch 400: Loss 0.2321\n",
            "Epoch 3, Batch 450: Loss 0.3318\n",
            "Epoch 3, Batch 500: Loss 0.1345\n",
            "Epoch 3, Batch 550: Loss 0.0830\n",
            "Epoch 3, Batch 600: Loss 0.2200\n",
            "Epoch 3, Batch 650: Loss 0.1932\n",
            "Epoch 3, Batch 700: Loss 0.5687\n",
            "Epoch 3/10, Avg Loss: 0.2471\n",
            "Epoch 4, Batch 0: Loss 0.1668\n",
            "Epoch 4, Batch 50: Loss 0.4014\n",
            "Epoch 4, Batch 100: Loss 0.2016\n",
            "Epoch 4, Batch 150: Loss 0.2248\n",
            "Epoch 4, Batch 200: Loss 0.1499\n",
            "Epoch 4, Batch 250: Loss 0.2459\n",
            "Epoch 4, Batch 300: Loss 0.1308\n",
            "Epoch 4, Batch 350: Loss 0.1471\n",
            "Epoch 4, Batch 400: Loss 0.1790\n",
            "Epoch 4, Batch 450: Loss 0.1872\n",
            "Epoch 4, Batch 500: Loss 0.2946\n",
            "Epoch 4, Batch 550: Loss 0.1623\n",
            "Epoch 4, Batch 600: Loss 0.2453\n",
            "Epoch 4, Batch 650: Loss 0.2547\n",
            "Epoch 4, Batch 700: Loss 0.3279\n",
            "Epoch 4/10, Avg Loss: 0.2420\n",
            "Epoch 5, Batch 0: Loss 0.1549\n",
            "Epoch 5, Batch 50: Loss 0.2197\n",
            "Epoch 5, Batch 100: Loss 0.2438\n",
            "Epoch 5, Batch 150: Loss 0.3265\n",
            "Epoch 5, Batch 200: Loss 0.4535\n",
            "Epoch 5, Batch 250: Loss 0.0453\n",
            "Epoch 5, Batch 300: Loss 0.0839\n",
            "Epoch 5, Batch 350: Loss 0.2057\n",
            "Epoch 5, Batch 400: Loss 0.3587\n",
            "Epoch 5, Batch 450: Loss 0.2486\n",
            "Epoch 5, Batch 500: Loss 0.1690\n",
            "Epoch 5, Batch 550: Loss 0.3968\n",
            "Epoch 5, Batch 600: Loss 0.1062\n",
            "Epoch 5, Batch 650: Loss 0.1753\n",
            "Epoch 5, Batch 700: Loss 0.1019\n",
            "Epoch 5/10, Avg Loss: 0.2372\n",
            "Epoch 6, Batch 0: Loss 0.3225\n",
            "Epoch 6, Batch 50: Loss 0.1159\n",
            "Epoch 6, Batch 100: Loss 0.1623\n",
            "Epoch 6, Batch 150: Loss 0.1179\n",
            "Epoch 6, Batch 200: Loss 0.1236\n",
            "Epoch 6, Batch 250: Loss 0.2249\n",
            "Epoch 6, Batch 300: Loss 0.2397\n",
            "Epoch 6, Batch 350: Loss 0.0954\n",
            "Epoch 6, Batch 400: Loss 0.1435\n",
            "Epoch 6, Batch 450: Loss 0.2351\n",
            "Epoch 6, Batch 500: Loss 0.3088\n",
            "Epoch 6, Batch 550: Loss 0.0428\n",
            "Epoch 6, Batch 600: Loss 0.2567\n",
            "Epoch 6, Batch 650: Loss 0.2457\n",
            "Epoch 6, Batch 700: Loss 0.0853\n",
            "Epoch 6/10, Avg Loss: 0.2344\n",
            "Epoch 7, Batch 0: Loss 0.1413\n",
            "Epoch 7, Batch 50: Loss 0.2053\n",
            "Epoch 7, Batch 100: Loss 0.1102\n",
            "Epoch 7, Batch 150: Loss 0.1147\n",
            "Epoch 7, Batch 200: Loss 0.1534\n",
            "Epoch 7, Batch 250: Loss 0.3074\n",
            "Epoch 7, Batch 300: Loss 0.2459\n",
            "Epoch 7, Batch 350: Loss 0.0773\n",
            "Epoch 7, Batch 400: Loss 0.3120\n",
            "Epoch 7, Batch 450: Loss 0.2352\n",
            "Epoch 7, Batch 500: Loss 0.2908\n",
            "Epoch 7, Batch 550: Loss 0.2670\n",
            "Epoch 7, Batch 600: Loss 0.2446\n",
            "Epoch 7, Batch 650: Loss 0.1716\n",
            "Epoch 7, Batch 700: Loss 0.2677\n",
            "Epoch 7/10, Avg Loss: 0.2433\n",
            "Epoch 8, Batch 0: Loss 0.2199\n",
            "Epoch 8, Batch 50: Loss 0.1691\n",
            "Epoch 8, Batch 100: Loss 0.2076\n",
            "Epoch 8, Batch 150: Loss 0.3222\n",
            "Epoch 8, Batch 200: Loss 0.2989\n",
            "Epoch 8, Batch 250: Loss 0.1593\n",
            "Epoch 8, Batch 300: Loss 0.3018\n",
            "Epoch 8, Batch 350: Loss 0.6363\n",
            "Epoch 8, Batch 400: Loss 0.1550\n",
            "Epoch 8, Batch 450: Loss 0.2884\n",
            "Epoch 8, Batch 500: Loss 0.0674\n",
            "Epoch 8, Batch 550: Loss 0.4144\n",
            "Epoch 8, Batch 600: Loss 0.2837\n",
            "Epoch 8, Batch 650: Loss 0.4031\n",
            "Epoch 8, Batch 700: Loss 0.3300\n",
            "Epoch 8/10, Avg Loss: 0.2405\n",
            "Epoch 9, Batch 0: Loss 0.0780\n",
            "Epoch 9, Batch 50: Loss 0.2982\n",
            "Epoch 9, Batch 100: Loss 0.2343\n",
            "Epoch 9, Batch 150: Loss 0.4388\n",
            "Epoch 9, Batch 200: Loss 0.1690\n",
            "Epoch 9, Batch 250: Loss 0.2058\n",
            "Epoch 9, Batch 300: Loss 0.1169\n",
            "Epoch 9, Batch 350: Loss 0.1205\n",
            "Epoch 9, Batch 400: Loss 0.4031\n",
            "Epoch 9, Batch 450: Loss 0.2436\n",
            "Epoch 9, Batch 500: Loss 0.2748\n",
            "Epoch 9, Batch 550: Loss 0.2005\n",
            "Epoch 9, Batch 600: Loss 0.3041\n",
            "Epoch 9, Batch 650: Loss 0.0828\n",
            "Epoch 9, Batch 700: Loss 0.1892\n",
            "Epoch 9/10, Avg Loss: 0.2380\n",
            "Epoch 10, Batch 0: Loss 0.2155\n",
            "Epoch 10, Batch 50: Loss 0.2097\n",
            "Epoch 10, Batch 100: Loss 0.3545\n",
            "Epoch 10, Batch 150: Loss 0.1968\n",
            "Epoch 10, Batch 200: Loss 0.3122\n",
            "Epoch 10, Batch 250: Loss 0.3676\n",
            "Epoch 10, Batch 300: Loss 0.1807\n",
            "Epoch 10, Batch 350: Loss 0.1220\n",
            "Epoch 10, Batch 400: Loss 0.4236\n",
            "Epoch 10, Batch 450: Loss 0.1878\n",
            "Epoch 10, Batch 500: Loss 0.1618\n",
            "Epoch 10, Batch 550: Loss 0.1091\n",
            "Epoch 10, Batch 600: Loss 0.1724\n",
            "Epoch 10, Batch 650: Loss 0.0902\n",
            "Epoch 10, Batch 700: Loss 0.1942\n",
            "Epoch 10/10, Avg Loss: 0.2392\n",
            "Model saved with GPU-trained weights\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy evaluation\n",
        "def calculate_accuracy(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
        "            outputs = model(inputs)\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return 100 * correct / total\n",
        "\n",
        "train_acc = calculate_accuracy(train_loader)\n",
        "test_acc = calculate_accuracy(test_loader)\n",
        "\n",
        "print(f'Training Accuracy: {train_acc:.2f}%')\n",
        "print(f'Test Accuracy: {test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmH_qyFv8SPl",
        "outputId": "6b9e5e84-fe56-4033-c2b3-5a42c4205284"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 92.86%\n",
            "Test Accuracy: 91.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Quick restart- in order to avoid training the model again\n",
        "# Mount Drive & check GPU\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoJR4Yof9K45",
        "outputId": "b33f5d03-63e8-4501-fc43-463cb58912ea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Load the saved model\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "model = models.mobilenet_v2(pretrained=False)\n",
        "model.classifier[1] = nn.Sequential(\n",
        "    nn.Linear(model.classifier[1].in_features, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/waste_model_gpu.pth'))\n",
        "model = model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU9hfrdPc1KH",
        "outputId": "6715d57a-2c79-46d2-994e-9c862fdfaa2d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): Conv2dNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Sequential(\n",
              "      (0): Linear(in_features=1280, out_features=1, bias=True)\n",
              "      (1): Sigmoid()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify loading\n",
        "print(\"Model loaded successfully!\")\n",
        "print(f\"Device: {next(model.parameters()).device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUeaLum8dCbQ",
        "outputId": "2b93927b-8d4e-4fe3-cf0c-c89f260a40e0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n",
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to Google Drive (permanent storage)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/waste_model_mobilenet.pth')\n",
        "print(\"MobileNetV2 model saved to Google Drive\")"
      ],
      "metadata": {
        "id": "j1dKTbqZdOSK",
        "outputId": "f2399257-64bd-47f8-e70c-c9d7f59820d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNetV2 model saved to Google Drive\n"
          ]
        }
      ]
    }
  ]
}