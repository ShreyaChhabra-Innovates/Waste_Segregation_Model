# -*- coding: utf-8 -*-
"""Waste_Segregation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LjBN5Xum0PHei4EFH7WUx9-Jn58qvIKm
"""

import torch

# Check if CUDA (GPU support) is available
if torch.cuda.is_available():
    device = torch.device("cuda")
    print(f"GPU is enabled: {torch.cuda.get_device_name(0)}")
else:
    device = torch.device("cpu")
    print("GPU not available, using CPU instead")

from google.colab import drive
drive.mount('/content/drive')

!pip install torch torchvision pillow matplotlib

# First uninstall existing packages
#!pip uninstall torch torchvision -y

# Then reinstall with --no-cache-dir flag
!pip install torch torchvision pillow matplotlib --no-cache-dir

from torchvision import transforms
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import os
import matplotlib.pyplot as plt

# Image preprocessing
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

#Our Custom Dataset
class WasteDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.classes = ['O', 'R']  # O=Organic, R=Recyclable
        self.image_paths = []

        for i, class_name in enumerate(self.classes):
            class_dir = os.path.join(root_dir, class_name)
            for img_name in os.listdir(class_dir):
                self.image_paths.append((os.path.join(class_dir, img_name), i))

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path, label = self.image_paths[idx]
        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        return image, torch.tensor(label, dtype=torch.float32)

#unzip the dataset
!unzip -q "/content/drive/MyDrive/waste-classification-data.zip" -d "/content/dataset"

train_dataset = WasteDataset('/content/dataset/DATASET/TRAIN', transform=transform)
test_dataset = WasteDataset('/content/dataset/DATASET/TEST', transform=transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model = models.mobilenet_v2(pretrained=True)
for param in model.parameters():
    param.requires_grad = False

model.classifier[1] = nn.Sequential(
    nn.Linear(model.classifier[1].in_features, 1),
    nn.Sigmoid()
).to(device)  # Move classifier to GPU immediately

model = model.to(device)  # Move entire model to GPU
print(f"Model moved to: {next(model.parameters()).device}")

criterion = nn.BCELoss()
optimizer = optim.Adam(model.classifier[1].parameters(), lr=0.001)

# Enhanced training loop with GPU and progress tracking
num_epochs = 10
train_losses = []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for batch_idx, (inputs, labels) in enumerate(train_loader):
        # Move data to GPU in batches
        inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # Print every 50 batches
        if batch_idx % 50 == 0:
            print(f'Epoch {epoch+1}, Batch {batch_idx}: Loss {loss.item():.4f}')

    epoch_loss = running_loss/len(train_loader)
    train_losses.append(epoch_loss)
    print(f'Epoch {epoch+1}/{num_epochs}, Avg Loss: {epoch_loss:.4f}')

# Save model
torch.save(model.state_dict(), '/content/drive/MyDrive/waste_model_gpu.pth')
print("Model saved with GPU-trained weights")

# Plot training progress
plt.plot(range(1, num_epochs+1), train_losses)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Progress')
plt.show()

#accuracy evaluation
def calculate_accuracy(loader):
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, labels in loader:
            inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)
            outputs = model(inputs)
            predicted = (outputs > 0.5).float()
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    return 100 * correct / total

train_acc = calculate_accuracy(train_loader)
test_acc = calculate_accuracy(test_loader)

print(f'Training Accuracy: {train_acc:.2f}%')
print(f'Test Accuracy: {test_acc:.2f}%')

#Quick restart- in order to avoid training the model again
# Mount Drive & check GPU
from google.colab import drive
drive.mount('/content/drive')

import torch
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Cell 2: Load the saved model
from torchvision import models
import torch.nn as nn

model = models.mobilenet_v2(pretrained=False)
model.classifier[1] = nn.Sequential(
    nn.Linear(model.classifier[1].in_features, 1),
    nn.Sigmoid()
).to(device)

model.load_state_dict(torch.load('/content/drive/MyDrive/waste_model_gpu.pth'))
model = model.to(device)
model.eval()

#Verify loading
print("Model loaded successfully!")
print(f"Device: {next(model.parameters()).device}")

# Save to Google Drive (permanent storage)
torch.save(model.state_dict(), '/content/drive/MyDrive/waste_model_mobilenet.pth')
print("MobileNetV2 model saved to Google Drive")